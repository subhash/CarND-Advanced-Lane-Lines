{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "dir = \"camera_cal\"\n",
    "images = [mpimg.imread(f) for f in glob.glob(os.path.join(dir, \"calibration*.jpg\"))]    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def display_images(images, cmap=None, col=4, title=None):\n",
    "    row = (len(images)-1)//col + 1\n",
    "    gs = gridspec.GridSpec(row, col)\n",
    "    fig = plt.figure(figsize=(30,10))\n",
    "    #if title: fig.suptitle(title, fontsize=24, fontweight='bold')\n",
    "    for im,g in zip(images, gs):\n",
    "        s = fig.add_subplot(g)\n",
    "        s.imshow(im, cmap=cmap)\n",
    "        if title: s.set_title(title)\n",
    "    gs.tight_layout(fig)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def findChessboardCorners(im, dim):\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "    found, corners = cv2.findChessboardCorners(gray, dim, None)\n",
    "    ret = cv2.drawChessboardCorners(np.copy(im), dim, corners, found) if found else im\n",
    "    return ret, found, corners\n",
    "\n",
    "def calibrateCamera(images):\n",
    "    r, c = (9,6)\n",
    "    processed = np.vstack([findChessboardCorners(im, (r, c)) for im in images])\n",
    "    valid = processed[processed[:,1]==True]\n",
    "    image_shape = valid[0, 0].shape\n",
    "    image_points = np.array([v.squeeze() for v in valid[:,2]])\n",
    "    coords = np.zeros((r*c,3), np.float32)\n",
    "    coords[:,:2] = np.mgrid[:r, :c].T.reshape(-1, 2)\n",
    "    object_points = np.tile(coords, (image_points.shape[0], 1, 1))\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(object_points, image_points, image_shape[0:2], None, None)\n",
    "    return ret, mtx, dist, rvecs, tvecs, valid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calibrate\n",
    "ret, mtx, dist, rvecs, tvecs, valid = calibrateCamera(images)\n",
    "#display_images(valid[:,0])\n",
    "\n",
    "# Undistort\n",
    "sample_image = images[0]\n",
    "dst = cv2.undistort(sample_image, mtx, dist, None, mtx)\n",
    "plt.imshow(sample_image)\n",
    "plt.figure()\n",
    "plt.imshow(dst)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_channels(im):\n",
    "    gray = cv2.cvtColor(im, cv2.COLOR_RGB2GRAY)\n",
    "    hls = cv2.cvtColor(im, cv2.COLOR_RGB2HLS)\n",
    "    hsv = cv2.cvtColor(im, cv2.COLOR_RGB2HSV)\n",
    "    yuv = cv2.cvtColor(im, cv2.COLOR_RGB2YUV)\n",
    "    gg, r, g, b, h, l, s, hh, ss, vv, y, u, yv = [\n",
    "        gray, im[:,:,0], im[:,:,1], im[:,:,2], \n",
    "        hls[:,:,0], hls[:,:,1], hls[:,:,2], \n",
    "        hsv[:,:,0], hsv[:,:,1], hsv[:,:,2],\n",
    "        yuv[:,:,0], yuv[:,:,1], yuv[:,:,2]]\n",
    "    return gg, r, g, b, h, l, s, hh, ss, vv, y, u, yv\n",
    "\n",
    "test_dir = \"test_images\"\n",
    "straight_lines1 = mpimg.imread(os.path.join(test_dir, \"straight_lines1.jpg\"))\n",
    "straight_lines2 = mpimg.imread(os.path.join(test_dir, \"straight_lines2.jpg\"))\n",
    "channels = extract_channels(straight_lines1)\n",
    "display_images(channels[0:1], 'gray', col=1, title=\"Gray\")\n",
    "display_images(channels[1:4], 'gray', col=3, title=\"RGB\")\n",
    "display_images(channels[4:7], 'gray', col=3, title=\"HLS\")\n",
    "display_images(channels[7:10], 'gray', col=3, title=\"HSV\")\n",
    "display_images(channels[10:13], 'gray', col=3, title=\"YUV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_images = [mpimg.imread(f) for f in glob.glob(os.path.join(test_dir, \"test*.jpg\"))]\n",
    "display_images(test_images, col=3, title=\"Test images\")\n",
    "l_channels = [extract_channels(im)[5] for im in test_images]\n",
    "s_channels = [extract_channels(im)[6] for im in test_images]\n",
    "display_images(l_channels, col=3, title=\"L channel only\", cmap='gray')\n",
    "display_images(s_channels, col=3, title=\"S channel only\", cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def simple_norm(im):\n",
    "    return im/np.max(im)\n",
    "\n",
    "def threshold(im, mn, mx):\n",
    "    im = im.astype(np.float32)\n",
    "    norm = simple_norm(im)\n",
    "    fltr = np.logical_and(norm >= mn, norm <= mx)\n",
    "    #fltr = np.logical_and(im >= mn*255, im <= mx*255)\n",
    "    thresh = np.zeros_like(im, dtype=np.float32)\n",
    "    #thresh[fltr] = 1\n",
    "    thresh[fltr] = norm[fltr]\n",
    "    return thresh\n",
    "\n",
    "def threshold_color(im):\n",
    "    channels = extract_channels(im)\n",
    "    _, r, g, b, h, l, s, hh, ss, vv, y, u, yv = channels\n",
    "    thresholded_r = threshold(r, 0.75, 1.0)\n",
    "    thresholded_s = threshold(s, 0.75, 1.0)\n",
    "    thresholded_l = threshold(l, 0.90, 1.0)\n",
    "    thresholded_ss = threshold(ss, 0.70, 1.0)\n",
    "    thresholded_vv = threshold(vv, 0.90, 1.0)\n",
    "    thresholded_y = threshold(y, 0.90, 1.0)\n",
    "    return thresholded_s, thresholded_l, thresholded_r, thresholded_vv, thresholded_y\n",
    "\n",
    "def gradients(img, ksize=13):\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    #gray = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)[:,:,1]\n",
    "    gray = np.uint8(img)\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=ksize)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=ksize)\n",
    "    abs_sobel_x = np.absolute(sobel_x)\n",
    "    abs_sobel_y = np.absolute(sobel_y)\n",
    "    magnitude = np.sqrt(sobel_x**2 + sobel_y**2)\n",
    "    direction = np.arctan2(abs_sobel_y, abs_sobel_x)\n",
    "    return abs_sobel_x, abs_sobel_y, magnitude, direction\n",
    "\n",
    "def threshold_gradients(im):\n",
    "    x_grad, y_grad, mag_grad, dir_grad = gradients(im)\n",
    "    x_grad = threshold(x_grad, 0.3, 1.0)\n",
    "    y_grad = threshold(y_grad, 0.3, 1.0)\n",
    "    mag_grad = threshold(mag_grad, 0.3, 1.0)\n",
    "    dir_grad = threshold(dir_grad, 0.5, 0.8)\n",
    "    return x_grad, y_grad, mag_grad, dir_grad\n",
    "\n",
    "def threshold_pipeline(im):\n",
    "    undist = cv2.undistort(im, mtx, dist, None, mtx)\n",
    "    thresh_s, thresh_l, thresh_r, thresh_vv, thresh_y = threshold_color(im)\n",
    "    color_combined = np.logical_or(thresh_s, thresh_l)\n",
    "    x_grad, y_grad, mag_grad, dir_grad = threshold_gradients(color_combined)\n",
    "    grad_combined = np.logical_and(x_grad, y_grad)\n",
    "    dir_combined = np.logical_and(dir_grad, mag_grad)\n",
    "    combined = np.logical_or(grad_combined, dir_combined)\n",
    "    \n",
    "    #thresh_image = threshold(combined, 0.3, 1.0)\n",
    "    thresh_image = np.dstack((x_grad, y_grad, dir_grad))\n",
    "    return combined\n",
    "\n",
    "# thresh_images, thresh_s, thresh_color, combined_grad = zip(*[threshold_pipeline(im) for im in test_images])\n",
    "# display_images(thresh_color, col=3, cmap='gray', title='Combined Channels')\n",
    "# # diff = [c - s for c, s in zip(thresh_color, thresh_s)]\n",
    "# # display_images(diff, col=3, cmap='gray', title='Diff Channels')\n",
    "# display_images(combined_grad, col=3, cmap='gray', title=\"Combined gradient\")\n",
    "# display_images(thresh_images, col=3, cmap='gray', title=\"Thresholded\")\n",
    "\n",
    "thresh_images = [threshold_pipeline(im) for im in test_images]\n",
    "#display_images(test_images, col=3)\n",
    "display_images(thresh_images, cmap='gray', col= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    def mask_image(im):\n",
    "        im = np.uint8(im)\n",
    "        mask = np.zeros_like(im)\n",
    "        vertices = np.array([[[180,720],[570,450],[710,450],[1190,720]]], dtype=np.int32 )\n",
    "        cv2.fillPoly(mask, vertices, 255)\n",
    "        return cv2.bitwise_and(mask, im)\n",
    "\n",
    "    def warp_image(im):\n",
    "        #src = np.float32([[190,720],[580,450],[700,450],[1170,720]])\n",
    "        src = np.float32([[200,720],[590,450],[690,450],[1100,720]])\n",
    "        dst = np.float32([[200,720],[200,0],[1080,0],[1080,720]])    \n",
    "        maxy, maxx = im.shape\n",
    "        M = cv2.getPerspectiveTransform(src, dst)\n",
    "        unsigned = np.uint8(im)\n",
    "        warped = cv2.warpPerspective(unsigned, M, (maxx, maxy), flags=cv2.INTER_LINEAR)\n",
    "        return warped, src, dst\n",
    "\n",
    "    def unwarp_image(im, src, dst):\n",
    "        maxy, maxx = im.shape[0], im.shape[1] \n",
    "        unsigned = np.uint8(im)    \n",
    "        Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "        unwarped = cv2.warpPerspective(unsigned, Minv, (maxx, maxy), flags=cv2.INTER_LINEAR)\n",
    "        return unwarped\n",
    "\n",
    "    def plot_warped(im, warped, src, dst):\n",
    "        plt.imshow(im, cmap='gray')\n",
    "        plt.title(\"Transform\")\n",
    "        plt.plot(*zip(src[0], src[1]), 'r-')\n",
    "        plt.plot(*zip(src[2], src[3]), 'r-')\n",
    "        plt.figure()\n",
    "        plt.imshow(warped, cmap='gray')\n",
    "        plt.title(\"Warped\")    \n",
    "        plt.plot(*zip(dst[0], dst[1]), 'r-')\n",
    "        plt.plot(*zip(dst[2], dst[3]), 'r-')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def plot_fit(out_img, left_fit, right_fit, color='yellow', title='Line fit'):\n",
    "        h,w,_ = out_img.shape\n",
    "        y_values = np.arange(h)\n",
    "        coeff = np.array([[y**2, y, 1] for y in y_values])\n",
    "        lx_values = np.dot(left_fit, coeff.T)\n",
    "        rx_values = np.dot(right_fit, coeff.T)\n",
    "\n",
    "        window_img = np.zeros_like(out_img)\n",
    "        l1points = np.vstack((lx_values-50, y_values)).T.astype(np.int32)\n",
    "        l2points = np.vstack((lx_values+50, y_values)).T.astype(np.int32)\n",
    "        r1points = np.vstack((rx_values-50, y_values)).T.astype(np.int32)\n",
    "        r2points = np.vstack((rx_values+50, y_values)).T.astype(np.int32)\n",
    "        lpoints = np.vstack((l1points, np.flipud(l2points)))\n",
    "        rpoints = np.vstack((r1points, np.flipud(r2points)))    \n",
    "        cv2.fillPoly(window_img, [lpoints], (0,255,0))\n",
    "        cv2.fillPoly(window_img, [rpoints], (0,255,0))    \n",
    "        result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "\n",
    "        plt.imshow(result)\n",
    "        plt.title(title)\n",
    "        plt.plot(lx_values, y_values, color=color)\n",
    "        plt.plot(rx_values, y_values, color=color)\n",
    "        plt.xlim(0, 1280)\n",
    "        plt.ylim(720, 0)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def slide_windows(im, out_img, slide_start, num_window, width_window, thresh=50):\n",
    "        imageh, imagew = im.shape\n",
    "        height_window = imageh//num_window\n",
    "        pos = slide_start\n",
    "        xpts, ypts = np.int8([]), np.int8([])\n",
    "        for w in range(num_window):\n",
    "            windex = num_window - w\n",
    "            lowx, lowy = pos-width_window//2, (windex-1)*height_window\n",
    "            highx, highy = pos+width_window//2, windex * height_window\n",
    "            nzy, nzx = np.nonzero(im[lowy:highy, lowx:highx])\n",
    "            xpts = np.append(xpts, nzx+lowx)\n",
    "            ypts = np.append(ypts, nzy+lowy)\n",
    "            if(len(nzx) > thresh):\n",
    "                best_index = np.int(np.mean(nzx))\n",
    "                pos = pos-width_window//2+best_index\n",
    "            cv2.rectangle(out_img, (lowx, lowy), (highx, highy), (0,255,0), 2)\n",
    "        return xpts, ypts\n",
    "\n",
    "    def search_for_fit(warped, out_img):\n",
    "        h,w = warped.shape\n",
    "        top, bottom = warped[:h//2,:], warped[h//2:,:]\n",
    "        hist_bottom = np.sum(bottom, axis=0)\n",
    "        left_bottom, right_bottom = np.argmax(hist_bottom[:w//2]), w//2+np.argmax(hist_bottom[w//2:])\n",
    "\n",
    "        lxp, lyp = slide_windows(warped, out_img, left_bottom, 9, 100)\n",
    "        rxp, ryp = slide_windows(warped, out_img, right_bottom, 9, 100)\n",
    "        out_img[lyp, lxp] = [255,0,0]\n",
    "        out_img[ryp, rxp] = [0,0,255]\n",
    "\n",
    "        left_fit = np.polyfit(lyp, lxp, 2)\n",
    "        right_fit = np.polyfit(ryp, rxp, 2)\n",
    "\n",
    "        return left_fit, right_fit, lxp, lyp, rxp, ryp, left_bottom, right_bottom\n",
    "\n",
    "    def search_around_fit(im, lfit, rfit, margin=50):\n",
    "        nzy, nzx = np.nonzero(im)\n",
    "        coeff = np.array([[y**2, y, 1] for y in nzy])    \n",
    "        plx = np.dot(lfit, coeff.T)\n",
    "        prx = np.dot(rfit, coeff.T)\n",
    "        lcond = (nzx-margin < plx) & (nzx+margin > plx)\n",
    "        rcond = (nzx-margin < prx) & (nzx+margin > prx)\n",
    "        nlfit = np.polyfit(nzy[lcond], nzx[lcond], 2)\n",
    "        nrfit = np.polyfit(nzy[rcond], nzx[rcond], 2)\n",
    "        lx, ly, rx, ry = nzx[lcond], nzy[lcond], nzx[rcond], nzy[rcond]\n",
    "        return nlfit, nrfit, lx, ly, rx, ry\n",
    "\n",
    "    def real_fit(x, y):\n",
    "        ym_per_pix = 30/720\n",
    "        xm_per_pix = 3.7/700\n",
    "        fit = np.polyfit(y*ym_per_pix, x*xm_per_pix, 2)\n",
    "        return fit\n",
    "\n",
    "    def radius_of_curvature(fit, y):\n",
    "        a, b, c = fit\n",
    "        return ((1+(2*a*y+b)**2)**(3/2))/np.absolute(2*a)\n",
    "\n",
    "    #im = thresh_images[2]\n",
    "    im = threshold_pipeline(export_images[8])\n",
    "\n",
    "    warped, src, dst = warp_image(im)\n",
    "    plot_warped(im, warped, src, dst)\n",
    "\n",
    "    out_img = np.dstack((warped, warped, warped))*255\n",
    "    lfit, rfit, lx, ly, rx, ry, _ , _ = search_for_fit(warped, out_img)\n",
    "    real_lfit = real_fit(lx, ly)\n",
    "    real_rfit = real_fit(rx, ry)\n",
    "    plt.imshow(out_img)\n",
    "    plt.title(\"Sliding windows\")\n",
    "    plt.show()\n",
    "\n",
    "    out_img = np.dstack((warped, warped, warped))*255\n",
    "    plot_fit(out_img, lfit, rfit, title='Sliding window fit')\n",
    "    nlfit, nrfit, nlx, nly, nrx, nry = search_around_fit(warped, lfit, rfit)\n",
    "    plot_fit(out_img, nlfit, nrfit, title='Smoother fit') \n",
    "\n",
    "    rl, rr = radius_of_curvature(real_lfit, im.shape[0]), radius_of_curvature(real_rfit, im.shape[0])\n",
    "    print(rl, 'm ', rr, 'm ')\n",
    "\n",
    "    print(lfit, rfit)\n",
    "    print(nlfit, nrfit)\n",
    "    print(len(lx), len(ly), len(rx), len(ry))\n",
    "    print(len(nlx), len(nly), len(nrx), len(nry))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def offset_from_centre(x, y, real_lfit, real_rfit):\n",
    "    ym_per_pix = 30/720\n",
    "    xm_per_pix = 3.7/700\n",
    "    xm, ym = x*xm_per_pix, y*ym_per_pix\n",
    "    coeff = [ym**2, ym, 1]\n",
    "    lx = np.dot(real_lfit, coeff)\n",
    "    rx = np.dot(real_rfit, coeff)\n",
    "    return xm - (rx+lx)/2\n",
    "\n",
    "def lane_mask(im, lfit, rfit):\n",
    "    h, w, _ = im.shape\n",
    "    y_values = np.arange(h)\n",
    "    coeff = np.array([[y**2, y, 1] for y in y_values])\n",
    "    lx_values = np.dot(lfit, coeff.T)\n",
    "    rx_values = np.dot(rfit, coeff.T)\n",
    "\n",
    "    color_warp = np.zeros_like(im).astype(np.uint8)\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([lx_values, y_values]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([rx_values, y_values])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    return unwarp_image(color_warp, src, dst)\n",
    "\n",
    "\n",
    "def annotate_image(im):\n",
    "    thresh = threshold_pipeline(im)\n",
    "    warped, src, dst = warp_image(thresh)\n",
    "    out_img = np.dstack((warped, warped, warped))*255\n",
    "    lfit, rfit, lx, ly, rx, ry, _, _ = search_for_fit(warped, out_img)\n",
    "    #lfit, rfit, lx, ly, rx, ry = search_around_fit(warped, lfit, rfit)\n",
    "    \n",
    "    mask = lane_mask(im, lfit, rfit)\n",
    "\n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(im, 1, mask, 0.3, 0)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX    \n",
    "    h, w, _ = im.shape\n",
    "    \n",
    "    real_lfit, real_rfit = real_fit(lx, ly), real_fit(rx, ry)\n",
    "    rcl, rcr = radius_of_curvature(real_lfit, h), radius_of_curvature(real_rfit, h)    \n",
    "    off = offset_from_centre(w/2, h, real_lfit, real_rfit)\n",
    "    conf = str(len(lx)) + \" - \" + str(len(rx))    \n",
    "    cv2.putText(result, \"Radius (Left)      : \" + str(rcl), (100,50), font, 1.5, (255,255,255),2)    \n",
    "    cv2.putText(result, \"Radius (Right)     : \" + str(rcr), (100,100), font, 1.5, (255,255,255),2) \n",
    "    cv2.putText(result, \"Offset from centre : \" + str(off), (100,150), font, 1.5, (255,255,255),2) \n",
    "    cv2.putText(result, \"Confidence         : \" + str(conf), (100,200), font, 1.5, (255,255,255),2)  \n",
    "    \n",
    "    return result\n",
    "\n",
    "class Annotator:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.left_fit = np.array([])\n",
    "        self.right_fit = np.array([])\n",
    "        self.lx = []\n",
    "        self.ly = []\n",
    "        self.rx = []\n",
    "        self.ry = []\n",
    "        self.olx = []\n",
    "        self.oly = []\n",
    "        self.orx = []\n",
    "        self.ory = []\n",
    "        \n",
    "    def average_fit(self, lfit, rfit, lx, ly, rx, ry):\n",
    "        a, b, _ = np.average((lfit, rfit), axis=0, weights=(len(lx), len(rx)))\n",
    "        nlfit = np.array([a, b, lfit[-1]])\n",
    "        nrfit = np.array([a, b, rfit[-1]])\n",
    "        lcoeff = np.array([[y**2, y, 1] for y in ly])\n",
    "        rcoeff = np.array([[y**2, y, 1] for y in ry])\n",
    "        nlx = np.dot(nlfit, lcoeff.T)\n",
    "        nrx = np.dot(nrfit, rcoeff.T)\n",
    "        return nlfit, nrfit, nlx, ly, nrx, ry\n",
    "    \n",
    "    def validate_fit(self, lfit, rfit, lx, ly, rx, ry, bottom_width):\n",
    "        mx, mn = np.max((len(lx), len(rx))), np.min((len(lx), len(rx)))\n",
    "        if (mx < 8000 and self.left_fit.any() and self.right_fit.any()):\n",
    "            lfit, rfit = self.left_fit, self.right_fit\n",
    "            lx, ly, rx, ry = self.lx, self.ly, self.rx, self.ry\n",
    "        elif (mn < mx//2):\n",
    "            if len(lx) < len(rx):\n",
    "                lx = (rx - bottom_width)\n",
    "                ly = ry\n",
    "                lfit = np.polyfit(ly, lx, 2)\n",
    "            else:\n",
    "                rx = (lx + bottom_width)\n",
    "                ry = ly\n",
    "                rfit = np.polyfit(ry, rx, 2)\n",
    "        return lfit, rfit, lx, ly, rx, ry\n",
    "        \n",
    "    def choose_fit(self, im):\n",
    "        thresh = threshold_pipeline(im)\n",
    "        warped, src, dst = warp_image(thresh)\n",
    "        out_img = np.dstack((warped, warped, warped))*255\n",
    "        \n",
    "        lfit, rfit, lx, ly, rx, ry, lb, rb = search_for_fit(warped, out_img)\n",
    "        #lfit, rfit, lx, ly, rx, ry = search_around_fit(warped, lfit, rfit)\n",
    "        self.olx, self.oly, self.orx, self.ory = lx, ly, rx, ry\n",
    "        \n",
    "        bottom_width = rb - lb\n",
    "        #lfit, rfit, lx, ly, rx, ry = self.average_fit(lfit, rfit, lx, ly, rx, ry)        \n",
    "        lfit, rfit, lx, ly, rx, ry = self.validate_fit(lfit, rfit, lx, ly, rx, ry, bottom_width)\n",
    "        \n",
    "        self.left_fit, self.right_fit = lfit, rfit\n",
    "        self.lx, self.ly = lx, ly\n",
    "        self.rx, self.ry = rx, ry\n",
    "    \n",
    "    def annotate_image(self, im):\n",
    "        lfit, rfit, lx, ly, rx, ry = self.left_fit, self.right_fit, self.lx, self.ly, self.rx, self.ry\n",
    "        olx, oly, orx, ory = self.olx, self.oly, self.orx, self.ory\n",
    "        mask = lane_mask(im, lfit, rfit)\n",
    "\n",
    "        # Combine the result with the original image\n",
    "        result = cv2.addWeighted(im, 1, mask, 0.3, 0)\n",
    "\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX    \n",
    "        h, w, _ = im.shape\n",
    "\n",
    "        ave_fit = np.average((lfit, rfit), axis=0, weights=(len(lx), len(rx)))\n",
    "        yp = np.array(range(h))\n",
    "        xp = np.dot(ave_fit, np.array([[y**2, y, 1] for y in yp]).T)\n",
    "        real_ave_fit = real_fit(xp, yp)\n",
    "        rc = radius_of_curvature(real_ave_fit, h)\n",
    "        \n",
    "        real_lfit, real_rfit = real_fit(olx, oly), real_fit(orx, ory)\n",
    "        rcl, rcr = radius_of_curvature(real_lfit, h), radius_of_curvature(real_rfit, h)            \n",
    "        conf = str(len(olx)) + \" - \" + str(len(orx))\n",
    "        \n",
    "        off = offset_from_centre(w/2, h, real_lfit, real_rfit)\n",
    "        cv2.putText(result, \"Radius of curvature : \" + str(rc), (100,50), font, 1.5, (255,255,255),2)    \n",
    "        cv2.putText(result, \"Offset from centre  : \" + str(off), (100,100), font, 1.5, (255,255,255),2) \n",
    "        #cv2.putText(result, \"Confidence          : \" + str(conf), (100,150), font, 1.5, (255,255,255),2) \n",
    "        #cv2.putText(result, \"Radius of curvature : \" + str(rcl), (100,200), font, 1.5, (255,255,255),2)    \n",
    "        #cv2.putText(result, \"Radius of curvature : \" + str(rcr), (100,250), font, 1.5, (255,255,255),2)\n",
    "\n",
    "        return result\n",
    "    \n",
    "    def annotate_pipeline(self, image):\n",
    "        self.choose_fit(image)\n",
    "        return self.annotate_image(image)\n",
    "        \n",
    "\n",
    "im = export_images[8]    \n",
    "# plt.figure(figsize=(30,20))\n",
    "# plt.imshow(im)    \n",
    "# plt.show()\n",
    "plt.figure(figsize=(30,20))\n",
    "ann = Annotator()\n",
    "result = ann.annotate_pipeline(im)\n",
    "#result = annotate_image(im)\n",
    "plt.imshow(result)    \n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "export_images = [mpimg.imread(f) for f in glob.glob(os.path.join(\"exported\", \"frame103?.jpeg\"))]\n",
    "ann = Annotator()\n",
    "annotated = [ann.annotate_pipeline(im) for im in export_images]\n",
    "display_images(annotated)\n",
    "annotated = [annotate_image(im) for im in export_images]\n",
    "display_images(annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "video_output = 'see.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(Annotator().annotate_pipeline)\n",
    "%time white_clip.write_videofile(white_output, audio=False)\n",
    "\n",
    "# challenge = 'challenge-see.mp4'\n",
    "# clip1 = VideoFileClip(\"challenge_video.mp4\")\n",
    "# white_clip = clip1.fl_image(Annotator().annotate_pipeline)\n",
    "# %time white_clip.write_videofile(challenge, audio=False)\n",
    "\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(white_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
